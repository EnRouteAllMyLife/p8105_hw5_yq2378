---
title: "p8105_hw5_yq2378"
author: "Qi Yumeng"
date: "2023-11-12"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, load libraries}
library(tidyverse)
library(ggpubr)
library(patchwork)
```
# Problem 1 

```{r, load p1 data}
# loading data
homicide = read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

```{r, ttl homicide data by city}
homicide = homicide %>% 
  mutate(city_state = str_c(city, state, sep=", ")) 
ttl_bycity = homicide %>% 
  mutate(if_solved = if_else(disposition == "Closed by arrest",1,0 )) %>% 
  group_by(city) %>% summarise( ttl_cnt = n(), unsolved_cnt = n() - sum(if_solved), .groups = "keep") %>%
  arrange(desc(ttl_cnt)) 
ttl_bycity
```

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe

```{r, Baltimore case}
ttl_cnt = 2827
unsolved_cnt = 1825
prop_output = prop.test(x = unsolved_cnt, n = ttl_cnt)
broom::tidy(prop_output)
broom::tidy(prop_output) %>% pull(estimate)
broom::tidy(prop_output) %>% pull(conf.low, conf.high)
```

```{r, iteration}
CI_bycity = 
  ttl_bycity |>
  mutate(prop_output = map2(.x = unsolved_cnt, .y = ttl_cnt, prop.test),
         prop_output = map(prop_output,broom::tidy)) |> 
  unnest(prop_output) |>
  mutate(CI = paste("(",round(conf.low,4),", ", round(conf.high,4),")"),
         estimate = round(estimate, 4)) |>
  select(city, ttl_cnt, unsolved_cnt, estimate,CI, conf.low, conf.high)
CI_bycity
```

```{r, error_bar}
CI_bycity |>
  ggplot(aes(x = factor(city), y = estimate))+ 
  geom_point(size = 0.8) + 
  geom_errorbar(aes(ymin = conf.low,  ymax = conf.high), width = 0.2) + 
  coord_flip() + 
  theme_pubr() + xlab("City") + ylab("Estimate the Proportion of unsolved homicides") +
  theme(text = element_text(size = 8),
        plot.margin = unit(c(.1,.1,.1,.1),'cm'))

```

# Problem 2

```{r,load p2 data}
file_name = list.files(path = "./data")
file_name = paste("./data/",file_name, sep="")
study = tibble(
  arm = substr(file_name,8,10),
  subject_id = substr(file_name,12,13)) |>
  mutate(table = map(file_name, read.csv)) |>
  unnest(cols = "table") |>
  pivot_longer(cols = starts_with("week_"),
               names_to = "week",
               values_to = "values") |>
  mutate(week = substr(week, 6,6),
         week = as.numeric(week),
         arm = if_else(arm == "exp","experimental","control"),)
study
```

```{r,spaghetti PLOT!}
ggplot(data = study, aes(x = week, y = values, color = subject_id, linetype = arm)) +
  #geom_line(aes(subject_id), linewidth = 1) +
  geom_line(linewidth = 0.5)+
  theme_pubr(legend = "right") +
  labs(x = "Week Time", y = "Value") 
```

# Problem 3

```{r, generate data }
n = 30
sigma = 5
mu_seq = seq(0,6)
alpha = 0.05

simulation = 
  tibble(id = seq(1,5000*length(mu_seq)),
         mu = rep(mu_seq,each = 5000)) |>
  mutate(data = map(mu, \(mu) rnorm(n, mean = mu,sd = sigma)),
         t_test = map(data, \(x) t.test(x, alternative = "two.sided",
                                        mu = 0, paired = FALSE, conf.level = alpha)),
         t_test_result = map(t_test, broom::tidy)) |>
  unnest(cols = "t_test_result") |>
  select(id, mu, p.value, estimate)
  
```

In the context of a one-sample t-test, effect size is typically measured as the difference between the sample mean and the hypothesized population mean $\mu = 0$ divided by the standard deviation $sd = 5$. In this case, the effect size (in red color) is positively proportion to true value of $\mu$. As the effect size increases, the power increases, the most prominent change takes place around $\mu$ is around 1~3. As $\mu$ is higher than 4, that is the effect size higher than 0.8, the power reaches almost 100%.

```{r, power}
simulation |> 
  mutate(if_reject = if_else(p.value < alpha,1,0)) |>
  group_by(mu) |> 
  summarise(proportion = sum(if_reject)/5000) |>
  ggplot(aes(x = mu, y = proportion)) + 
  geom_point()+
  geom_line()+
  geom_text(aes(label = paste0(round(proportion * 100), "%")),vjust = -0.5)+
  geom_text(aes(label = round(mu/5 ,2)),vjust = 2, col = "red")+
  theme_pubr() + xlab("True Value of mu") + ylab("the Power of the Test") 
```

The sample average of $\hat{\mu}$ across tests for which the null is rejected provides an estimate of the population mean, but it is subject to randomness and variability. For example, the average estimate across samples where the null is rejected may deviate from the true value due to random sampling.  Larger effect sizes and larger sample sizes tend to yield more accurate estimates. Also, the rejection of the null hypothesis is based on statistical significance, indicating that the observed data is unlikely to have occurred by random chance alone. In summary, it is not guaranteed to be exactly equal to the true value of $\mu$, but it should be close to it on average.


```{r estimate mu vs actual}
p1 = 
  simulation |> 
  group_by(mu) |> 
  summarise(avg_mu = mean(estimate)) |>
  ggplot(aes(x = mu, y = avg_mu)) + 
  geom_point()+
  geom_text(aes(label = round(avg_mu ,2)),vjust = -0.5, col = "red")+
  theme_pubr() + xlab("True Value of mu") + ylab("Estimate Value of mu") 

p2 = 
  simulation |> 
  filter(p.value < alpha) |>
  group_by(mu) |> 
  summarise(avg_mu = mean(estimate)) |>
  ggplot(aes(x = mu, y = avg_mu)) + 
  geom_point()+
  geom_text(aes(label = round(avg_mu ,2)),vjust = -0.5, col = "red")+
  theme_pubr() + xlab("True Value of mu") + ylab("Estimate Value of mu") 
p1+p2
```

